{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tzf101/BDA-Bangla-Text-Data-Augmentation/blob/main/utils_notebook/EDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-9HyXADPmM_"
      },
      "source": [
        "#Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uR2IiCuSPATf",
        "outputId": "d16c699c-e533-4232-d955-b1223ec3be10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bnlp in /usr/local/lib/python3.10/dist-packages (0.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install bnlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3J-FfKSKPLtb",
        "outputId": "9b4c7518-49c6-4d8b-89f4-d0ac77ee07a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bnlp-toolkit in /usr/local/lib/python3.10/dist-packages (4.0.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (0.1.99)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (4.3.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (1.11.4)\n",
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (0.3.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (4.66.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (6.1.3)\n",
            "Requirement already satisfied: emoji==1.7.0 in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (1.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (2.31.0)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->bnlp-toolkit) (0.2.12)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->bnlp-toolkit) (6.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp-toolkit) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp-toolkit) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp-toolkit) (2023.6.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp-toolkit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp-toolkit) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp-toolkit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp-toolkit) (2023.11.17)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->bnlp-toolkit) (0.9.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->bnlp-toolkit) (1.16.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->bnlp-toolkit) (0.9.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install bnlp-toolkit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVf1OWelPxxz"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kU691Vo2PqQl"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from random import shuffle\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSC6zLkgP0qy"
      },
      "outputs": [],
      "source": [
        "from bnlp import BengaliCorpus as corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoYDv9rnW29q"
      },
      "outputs": [],
      "source": [
        "# import nltk\n",
        "# from nltk.corpus import wordnet\n",
        "# nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2G-ievdQW_Xd"
      },
      "outputs": [],
      "source": [
        "# def get_bangla_synonyms(word):\n",
        "#     synonyms = []\n",
        "#     for synset in wordnet.synsets(word, lang='bwn'):\n",
        "#         for lemma in synset.lemmas('ben'):\n",
        "#             synonyms.append(lemma.name())\n",
        "#     return list(set(synonyms))  # Remove duplicates\n",
        "\n",
        "# # Example usage\n",
        "# word_to_query = \"খুশি\"\n",
        "# synonyms = get_bangla_synonyms(word_to_query)\n",
        "\n",
        "# print(f\"Synonyms for '{word_to_query}': {synonyms}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVNwfW8atzaa"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHNz8_nfQXnB"
      },
      "outputs": [],
      "source": [
        "punc = corpus.punctuations + (\"‘\") + (\"’\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3jMglM5QL0Y"
      },
      "outputs": [],
      "source": [
        "STOPWORDS = set(corpus.stopwords)\n",
        "PUNCTUATIONS = set(punc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_UhrTa-aMq3"
      },
      "outputs": [],
      "source": [
        "class CleanText:\n",
        "    def __init__(self):\n",
        "        self.PUNCTUATIONS = set(punc)\n",
        "        self.STOPWORDS = set(corpus.stopwords)\n",
        "\n",
        "    def remove_digits(self, text):\n",
        "        return re.sub(r'[০-৯]+\\d+', '', text).strip()\n",
        "\n",
        "    def remove_punctuations(self, text, replace_with=\" \"):\n",
        "        for punc in self.PUNCTUATIONS:\n",
        "            text = text.replace(punc, replace_with)\n",
        "        return ' '.join(text.split())\n",
        "\n",
        "    def remove_stopwords(self, text):\n",
        "        words = text.split()\n",
        "        new_text = [word for word in words if word.lower() not in self.STOPWORDS]\n",
        "        return ' '.join(new_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DERvo-exevpE"
      },
      "outputs": [],
      "source": [
        "ct = CleanText()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1HzXYw6dkXD",
        "outputId": "35bc0664-77e8-44d6-e728-4c5a4e9d78f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "সঠিক তদন্ত করতে হবে বিচারের আওতায় আনতে হবে যে এই কাজ টা করেছে\n"
          ]
        }
      ],
      "source": [
        "text = \"সঠিক তদন্ত করতে হবে। বিচারের আওতায় আনতে হবে যে এই কাজ টা করেছে।\"\n",
        "# text_np = ct.remove_digits(text)\n",
        "text_np = ct.remove_punctuations(text)\n",
        "print(text_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzEOGSGLqnvi",
        "outputId": "91c172a7-371d-466c-fceb-3efb7121d747",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "words = text_np.split()\n",
        "len(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYUEEgyvdS38"
      },
      "source": [
        "# Random Deletion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRltGNk4dGQ7"
      },
      "outputs": [],
      "source": [
        "def random_deletion(text, p=0.3):\n",
        "    words = text.split()\n",
        "    #obviously, if there's only one word, don't delete it\n",
        "    if len(words) == 1:\n",
        "      return words\n",
        "\n",
        "    #randomly delete words with probability p\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "      r = random.uniform(0, 1)\n",
        "      if r > p:\n",
        "        new_words.append(word)\n",
        "\n",
        "    #if you end up deleting all words, just return a random word\n",
        "    if len(new_words) == 0:\n",
        "      rand_int = random.randint(0, len(words)-1)\n",
        "      return [words[rand_int]]\n",
        "\n",
        "    return ' '.join(new_words) + \"(rd)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otPtJgSLrTSw",
        "outputId": "77650cba-0bd8-4afd-c6a1-703be0485594",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "সঠিক তদন্ত করতে হবে বিচারের আওতায় আনতে যে এই করেছে(rd)\n"
          ]
        }
      ],
      "source": [
        "rd_text = random_deletion(text_np, 0.3)\n",
        "print(rd_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OswjrTKZr7ES"
      },
      "source": [
        "# Random Swap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3RhVC-DrgRZ"
      },
      "outputs": [],
      "source": [
        "def random_swap(text, n):\n",
        "    words = text.split()\n",
        "    new_words = words.copy()\n",
        "    for _ in range(n):\n",
        "      new_words = swap_word(new_words)\n",
        "    return ' '.join(new_words) + \"(rs)\"\n",
        "\n",
        "def swap_word(new_words):\n",
        "    random_idx_1 = random.randint(0, len(new_words)-1)\n",
        "    random_idx_2 = random.randint(0, len(new_words)-1)\n",
        "    counter = 0\n",
        "    while random_idx_2 == random_idx_1:\n",
        "      random_idx_2 = random.randint(0, len(new_words)-1)\n",
        "      counter += 1\n",
        "      if counter > 3:\n",
        "        return new_words\n",
        "    new_words[random_idx_1], new_words[random_idx_2] = new_words[random_idx_2], new_words[random_idx_1]\n",
        "    return new_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3_vZWq8tGJi",
        "outputId": "50805cbb-9bb2-4db7-bc42-bcd392839a6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "সঠিক কাজ করতে হবে বিচারের আওতায় আনতে হবে যে এই তদন্ত টা করেছে(rs)\n"
          ]
        }
      ],
      "source": [
        "rs_text = random_swap(text_np, 1)\n",
        "print(rs_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3TzK7W0ttnQ"
      },
      "source": [
        "# Synonym Replacement\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TR5F_xLuttQS"
      },
      "outputs": [],
      "source": [
        "#testing\n",
        "from bnlp import BengaliWord2Vec\n",
        "\n",
        "bwv = BengaliWord2Vec()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fN_ByHbv0Uw",
        "outputId": "f6183524-2289-4a2a-9738-b36549b7a91f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'গ্রামের', 'গ্রামে', 'মহল্লা', 'পুরসভা', 'তহসিল', 'তালুক', 'সংগ্রামপুর', 'মৌজা', 'গ্রামাঞ্চল', 'মৌজার'}\n"
          ]
        }
      ],
      "source": [
        "word = 'গ্রাম'\n",
        "syn = set()\n",
        "similar_words = bwv.get_most_similar_words(word, topn=10)\n",
        "for word in similar_words:\n",
        "  syn.add(word[0])\n",
        "print(syn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Olg7o5hgwiN3"
      },
      "outputs": [],
      "source": [
        "def synonym_replacement(text, n):\n",
        "    words = text.split()\n",
        "    new_words = words.copy()\n",
        "    random_word_list = list(set([word for word in words if word not in STOPWORDS]))\n",
        "    random.shuffle(random_word_list)\n",
        "    num_replaced = 0\n",
        "    for random_word in random_word_list:\n",
        "      synonyms = get_synonyms(random_word)\n",
        "      if len(synonyms) >= 1:\n",
        "        synonym = random.choice(list(synonyms))\n",
        "        new_words = [synonym if word == random_word else word for word in new_words]\n",
        "        #print(\"replaced\", random_word, \"with\", synonym)\n",
        "        num_replaced += 1\n",
        "      if num_replaced >= n: #only replace up to n words\n",
        "        break\n",
        "\n",
        "    #this is stupid but we need it, trust me\n",
        "    sentence = ' '.join(new_words)\n",
        "    new_words = sentence.split(' ')\n",
        "\n",
        "    return ' '.join(new_words) + \"(sr)\"\n",
        "\n",
        "def get_synonyms(word):\n",
        "    synonyms = set()\n",
        "    similar_words = bwv.get_most_similar_words(word, topn=10)\n",
        "    for word in similar_words:\n",
        "      synonyms.add(word[0])\n",
        "    if word in synonyms:\n",
        "      synonyms.remove(word)\n",
        "    return list(synonyms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9nS17urzSGR",
        "outputId": "81b5db0c-5464-4d10-f317-bb4df8d97114"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "সঠিক তদন্তের করতে হবে বিচারের আওতায় আনতে হবে যে এই কাজ ট্রুপ- করেছে(sr)\n"
          ]
        }
      ],
      "source": [
        "print(synonym_replacement(text_np, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wos3SQGuzx88"
      },
      "source": [
        "# Random Insertion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIEuvjgEztlm"
      },
      "outputs": [],
      "source": [
        "def random_insertion(text, n):\n",
        "    words = text.split()\n",
        "    new_words = words.copy()\n",
        "    for _ in range(n):\n",
        "      add_word(new_words)\n",
        "    return ' '.join(new_words) + \"(ri)\"\n",
        "\n",
        "def add_word(new_words):\n",
        "    synonyms = []\n",
        "    counter = 0\n",
        "    while len(synonyms) < 1:\n",
        "      random_word = new_words[random.randint(0, len(new_words)-1)]\n",
        "      synonyms = get_synonyms(random_word)\n",
        "      counter += 1\n",
        "      if counter >= 10:\n",
        "        return\n",
        "    random_synonym = synonyms[0]\n",
        "    random_idx = random.randint(0, len(new_words)-1)\n",
        "    new_words.insert(random_idx, random_synonym)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwlOYU9V0q6E",
        "outputId": "031f92c0-d6f4-474b-e6db-215b54a79e7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "সঠিক তদন্ত করতে হবে বিচারের আওতায় কিভাবে আনতে হবে যে এই কাজ টা শুনানি করেছে(ri)\n"
          ]
        }
      ],
      "source": [
        "print(random_insertion(text_np, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YKbLAYP0zbN"
      },
      "source": [
        "# Main Data Augmentation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pE4PglLF0t3u"
      },
      "outputs": [],
      "source": [
        "def eda(sentence, alpha_sr=0.1, alpha_ri=0.1, alpha_rs=0.1, p_rd=0.1, num_aug=9):\n",
        "\n",
        "    ct = CleanText()\n",
        "    text = ct.remove_punctuations(sentence)\n",
        "\n",
        "    words = text.split()\n",
        "    num_words = len(words)\n",
        "\n",
        "    augmented_sentences = []\n",
        "    num_new_per_technique = int(num_aug/4)+1\n",
        "\n",
        "    #sr\n",
        "    if (alpha_sr > 0):\n",
        "      n_sr = max(1, int(alpha_sr*num_words))\n",
        "      for _ in range(num_new_per_technique):\n",
        "        augmented_sentences.append(synonym_replacement(text, n_sr))\n",
        "\n",
        "    #ri\n",
        "    if (alpha_ri > 0):\n",
        "      n_ri = max(1, int(alpha_ri*num_words))\n",
        "      for _ in range(num_new_per_technique):\n",
        "        augmented_sentences.append(random_insertion(text, n_ri))\n",
        "\n",
        "    #rs\n",
        "    if (alpha_rs > 0):\n",
        "      n_rs = max(1, int(alpha_rs*num_words))\n",
        "      for _ in range(num_new_per_technique):\n",
        "        augmented_sentences.append(random_swap(text, n_rs))\n",
        "\n",
        "    # print(augmented_sentences)\n",
        "\n",
        "    #rd\n",
        "    if (p_rd > 0):\n",
        "      for _ in range(num_new_per_technique):\n",
        "        augmented_sentences.append(random_deletion(text, p_rd))\n",
        "\n",
        "    # print(augmented_sentences)\n",
        "\n",
        "    # augmented_sentences = [get_only_chars(sentence) for sentence in augmented_sentences]\n",
        "    shuffle(augmented_sentences)\n",
        "\n",
        "\n",
        "    #trim so that we have the desired number of augmented sentences\n",
        "    if num_aug >= 1:\n",
        "      augmented_sentences = augmented_sentences[:num_aug]\n",
        "    else:\n",
        "      keep_prob = num_aug / len(augmented_sentences)\n",
        "      augmented_sentences = [s for s in augmented_sentences if random.uniform(0, 1) < keep_prob]\n",
        "    #append the original sentence\n",
        "    augmented_sentences.append(sentence)\n",
        "\n",
        "    return augmented_sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-K79Nzmj20v6"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9yt7vyo22a9"
      },
      "outputs": [],
      "source": [
        "augs = eda(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNt62yiF66Ds",
        "outputId": "66a8913f-7d8d-4251-ce84-faada5861055"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "len(augs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLLxUe6P9D4n",
        "outputId": "e4a70a62-6c67-4cd1-e3a5-1ffdba545f5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "সঠিক তদন্ত বিচারের হবে করতে আওতায় আনতে হবে যে এই কাজ টা করেছে(rs)\n",
            "সঠিক তদন্ত করতে গ্রেফতারের হবে বিচারের আওতায় আনতে হবে যে এই কাজ টা করেছে(ri)\n",
            "সঠিক তদন্ত করতে হবে বিচারের আওতায় আনতে হবে যে এই কাজ টা পদ- করেছে(ri)\n",
            "সঠিক করতে হবে বিচারের আওতায় আনতে হবে যে এই টা করেছে(rd)\n",
            "টা তদন্ত করতে হবে বিচারের আওতায় আনতে হবে যে এই কাজ সঠিক করেছে(rs)\n",
            "সঠিক তদন্ত বিচারের আওতায় আনতে হবে যে এই কাজ করেছে(rd)\n",
            "সঠিক তদন্ত করতে হবে শুনানি বিচারের আওতায় আনতে হবে যে এই কাজ টা করেছে(ri)\n",
            "সঠিক তদন্ত করতে হবে বিচারের আওতায় আনতে হবে যে এই কাজ(rd)\n",
            "সঠিক তদন্ত এই হবে বিচারের আওতায় আনতে হবে যে করতে কাজ টা করেছে(rs)\n",
            "সঠিক তদন্ত করতে হবে। বিচারের আওতায় আনতে হবে যে এই কাজ টা করেছে।\n"
          ]
        }
      ],
      "source": [
        "for aug in augs:\n",
        "  print(aug)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRMVuqv6U1jc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}