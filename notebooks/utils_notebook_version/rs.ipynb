{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TzMyqYJ-MpZP",
        "AtDB5CFDbe-T",
        "nKUeTKEdNJSZ"
      ],
      "authorship_tag": "ABX9TyM+qMDXDLc7JwAEIHr441vG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tzf101/BDA-Bangla-Text-Data-Augmentation/blob/main/utils_notebook/rs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Libraries\n",
        "\n"
      ],
      "metadata": {
        "id": "TudFKonjbZRC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Libraries"
      ],
      "metadata": {
        "id": "TzMyqYJ-MpZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/MyDrive\", force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOeEB1YSMr6S",
        "outputId": "97f6c1c5-5dd1-4aee-a467-af97cc1828f4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece\n",
        "!pip install rouge\n",
        "!pip install sacrebleu\n",
        "!pip install -U sentence-transformers\n",
        "!pip install bert-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK7H47A1M0Iv",
        "outputId": "503849e5-c1c0-40e5-a44a-afbe8bb213d0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2.8.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.23.5)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: bert-score in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.1.0+cu121)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (1.5.3)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.35.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert-score) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.66.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert-score) (23.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2023.3.post1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.20.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.4.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (3.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2023.11.17)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.0.1->bert-score) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "import pandas as pd\n",
        "\n",
        "import sacrebleu\n",
        "from rouge import Rouge\n",
        "from sacrebleu import corpus_bleu\n",
        "from bert_score import score\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from nltk.translate.bleu_score import sentence_bleu"
      ],
      "metadata": {
        "id": "IBamt2QyM-rn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Models"
      ],
      "metadata": {
        "id": "AtDB5CFDbe-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sbert_model = SentenceTransformer('l3cube-pune/bengali-sentence-bert-nli')"
      ],
      "metadata": {
        "id": "kry4FrZlNBrJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Score calculation"
      ],
      "metadata": {
        "id": "nKUeTKEdNJSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_sbert_score(original, augmented):\n",
        "    emb1 = sbert_model.encode(original)\n",
        "    emb2 = sbert_model.encode(augmented)\n",
        "    cosine_scores = util.pytorch_cos_sim(emb1, emb2)\n",
        "    sbert_score = cosine_scores.item()\n",
        "    return sbert_score"
      ],
      "metadata": {
        "id": "rAR-9jrpNMK6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_scores(original, augmented):\n",
        "    # BLEU Score\n",
        "    reference = original\n",
        "    candidate = augmented\n",
        "    # bleu_score = sentence_bleu(reference, candidate)\n",
        "    bleu_score = [sacrebleu.corpus_bleu([aug], [[orig]]).score for aug, orig in zip(augmented, original)]\n",
        "    # BERTScore\n",
        "    P, R, F1 = score([augmented], [original], lang=\"bn\", rescale_with_baseline=True)\n",
        "\n",
        "    # SBERT Score with Cosine Similarity\n",
        "    emb1 = sbert_model.encode(original)\n",
        "    emb2 = sbert_model.encode(augmented)\n",
        "    cosine_scores = util.pytorch_cos_sim(emb1, emb2)\n",
        "    sbert_score = cosine_scores.item()\n",
        "\n",
        "    return bleu_score, F1.item(), sbert_score"
      ],
      "metadata": {
        "id": "9be5SZ92NOWF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RS function"
      ],
      "metadata": {
        "id": "AT_VrLx0NdNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bnlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rS37qbvAeVx4",
        "outputId": "ac371175-ee18-4605-fb91-e8150e0c7dc3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bnlp in /usr/local/lib/python3.10/dist-packages (0.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bnlp-toolkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4TpjxqphEX1",
        "outputId": "ff59ad8f-e24e-4d44-b114-6f6c97d390ed"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bnlp-toolkit in /usr/local/lib/python3.10/dist-packages (4.0.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (0.1.99)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (4.3.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (1.11.4)\n",
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (0.3.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (4.66.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (6.1.3)\n",
            "Requirement already satisfied: emoji==1.7.0 in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (1.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bnlp-toolkit) (2.31.0)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->bnlp-toolkit) (0.2.13)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->bnlp-toolkit) (6.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp-toolkit) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp-toolkit) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp-toolkit) (2023.6.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp-toolkit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp-toolkit) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp-toolkit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp-toolkit) (2023.11.17)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->bnlp-toolkit) (0.9.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->bnlp-toolkit) (1.16.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->bnlp-toolkit) (0.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from random import shuffle\n",
        "import re"
      ],
      "metadata": {
        "id": "MuR2C5hxey96"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bnlp import BengaliCorpus as corpus"
      ],
      "metadata": {
        "id": "Y4DAKpkDhMEE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bnlp import BengaliWord2Vec"
      ],
      "metadata": {
        "id": "buvlM9FLd9Ui"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RS():\n",
        "    def swap_word(self, new_words):\n",
        "        random_idx_1 = random.randint(0, len(new_words) - 1)\n",
        "        random_idx_2 = random.randint(0, len(new_words) - 1)\n",
        "        while random_idx_2 == random_idx_1:\n",
        "            random_idx_2 = random.randint(0, len(new_words) - 1)\n",
        "        new_words[random_idx_1], new_words[random_idx_2] = new_words[random_idx_2], new_words[random_idx_1]\n",
        "        return new_words\n",
        "\n",
        "    def augment(self, text, n, debug=False):\n",
        "        words = text.split()\n",
        "        new_words = words.copy()\n",
        "        for _ in range(n):\n",
        "            new_words = self.swap_word(new_words)\n",
        "        output =  ' '.join(new_words)\n",
        "        if debug:\n",
        "            output += \"(rs)\"\n",
        "        return output"
      ],
      "metadata": {
        "id": "OQLXTbNnkKXN"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing"
      ],
      "metadata": {
        "id": "aFoqvF4NTAWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rs = RS()\n",
        "text = \"সঠিক তদন্ত করতে হবে। বিচারের আওতায় আনতে হবে যে এই কাজ টা করেছে।\"\n",
        "augmented_text = rs.augment(text, n=2)\n",
        "print(augmented_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8wyLXLphtwO",
        "outputId": "bb333119-8c3e-4dd2-98dc-386588a4e1f2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "সঠিক বিচারের করতে হবে তদন্ত আওতায় আনতে হবে। যে এই কাজ টা করেছে।\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply RS on dataset"
      ],
      "metadata": {
        "id": "gT7mLqWyTFZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to apply paraphrasing\n",
        "def apply_rs(row):\n",
        "    return rs.augment(row['original_sentence'], n=2)"
      ],
      "metadata": {
        "id": "d2ZOcUu3TC9I"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sr_and_evaluate_dataset(file_path, original_col_name, new_col_name):\n",
        "    # Load the dataset\n",
        "    df = pd.read_csv(file_path)\n",
        "    df = df.rename(columns={original_col_name: 'original_sentence'})\n",
        "\n",
        "    # Apply the text augmentation function\n",
        "    df[new_col_name] = df.apply(apply_rs, axis=1)\n",
        "    # Compute ROUGE scores\n",
        "    rouge = Rouge()\n",
        "    rouge_scores = rouge.get_scores(df[new_col_name], df[\"original_sentence\"])\n",
        "    rouge_df = pd.DataFrame([\n",
        "        {\n",
        "            'r1p': score['rouge-1']['p'],\n",
        "            'r1r': score['rouge-1']['r'],\n",
        "            'r1f': score['rouge-1']['f'],\n",
        "            'r2p': score['rouge-2']['p'],\n",
        "            'r2r': score['rouge-2']['r'],\n",
        "            'r2f': score['rouge-2']['f'],\n",
        "            'rlp': score['rouge-l']['p'],\n",
        "            'rlr': score['rouge-l']['r'],\n",
        "            'rlf': score['rouge-l']['f'],\n",
        "        }\n",
        "        for score in rouge_scores\n",
        "    ])\n",
        "\n",
        "    # Compute SacreBLEU scores\n",
        "    sacrebleu_scores = [sacrebleu.corpus_bleu([aug], [[orig]]).score for aug, orig in zip(df[new_col_name], df[\"original_sentence\"])]\n",
        "    df[\"sacrebleu_score\"] = sacrebleu_scores\n",
        "\n",
        "    # SBERT Score with Cosine Similarity\n",
        "    df[\"sbert_score\"] = [calculate_sbert_score(orig, aug) for orig, aug in zip(df[\"original_sentence\"], df[new_col_name])]\n",
        "\n",
        "    # Combine the dataframes\n",
        "    result_df = pd.concat([df, rouge_df], axis=1)\n",
        "    result_df[\"method\"] = \"rs2\"\n",
        "\n",
        "    return result_df"
      ],
      "metadata": {
        "id": "V164XtxZTeWX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running on dataset"
      ],
      "metadata": {
        "id": "7e9HfvGMTqMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/MyDrive/MyDrive/Research/Thesis: BDA/Main/evaluation/(old)Youtube/Datasets/yt_sentiment_train_10.csv'"
      ],
      "metadata": {
        "id": "ksQrWUGiTrtl"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df = sr_and_evaluate_dataset(file_path, 'sentence1', 'augmented_sentence')"
      ],
      "metadata": {
        "id": "8WAr2BptTyaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df"
      ],
      "metadata": {
        "id": "HuiK-qrlT1yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving augmented dataset"
      ],
      "metadata": {
        "id": "NxB1ZH7mT8Vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.to_csv('/content/MyDrive/MyDrive/Research/Thesis: BDA/Main/evaluation/(old)Youtube/Datasets/yt_sentiment_train_10_rs.csv', index=False)"
      ],
      "metadata": {
        "id": "jBijEb-w2YH2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}